import os
import random
from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import numpy as np

# =================================================================
# === ì½”ë© í™˜ê²½ ì„¤ì •: ê²½ë¡œ ë° í•™ìŠµ ì„¤ì • (3ì°¨ í•™ìŠµìš©) ===
# =================================================================
# âš ï¸ Google Drive ë§ˆìš´íŠ¸ í›„ ê²½ë¡œë¥¼ í™•ì¸í•˜ì—¬ ìˆ˜ì •í•´ì£¼ì„¸ìš”.
NAVER_ROOT_DIR = r"D:\Crawling\Naver_Processed"
KAKAO_ROOT_DIR = r"D:\Crawling\Kakao_Processed"
PRETRAIN_PATH = r"D:\Webtoon_Models\webtoon_cnn_naver_finetuned_all.pt"
OUTPUT_MODEL_PATH = r"D:\Webtoon_Models\webtoon_cnn_naver_augmented_finetuned.pt" # 3ì°¨ í•™ìŠµ ìµœì¢… ëª¨ë¸ ì €ì¥ ê²½ë¡œ

# âœ… Batch Size ìµœì í™” í…ŒìŠ¤íŠ¸: 8 -> 16 -> 32 -> 64 ìˆœìœ¼ë¡œ ë³€ê²½í•˜ë©° OOM ì§ì „ ê°’ ì‚¬ìš©
BATCH_SIZE = 8
EPOCHS = 5
LR = 1e-5

# ë°ì´í„° ë¶„í•  ë¹„ìœ¨
VAL_RATIO = 0.2
TEST_RATIO = 0.2

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
NUM_WORKERS = 4 # ì½”ë© í™˜ê²½ì— ìµœì í™”

# =================================================================
# === ë°ì´í„°ì…‹ ë° í—¬í¼ í•¨ìˆ˜ === (ì´ì „ ì½”ë“œì™€ ë™ì¼)
# =================================================================

# í•™ìŠµìš© ì „ì²˜ë¦¬ (Augmentation ì ìš©)
transform_train = transforms.Compose([
    transforms.Resize((320, 320)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.1, contrast=0.1),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© ì „ì²˜ë¦¬ (Augmentation ì—†ì´ ê¸°ë³¸ ë³€í™˜)
transform_basic = transforms.Compose([
    transforms.Resize((320, 320)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

def collect_image_paths(base_dirs):
    image_paths = []
    if not isinstance(base_dirs, list): base_dirs = [base_dirs]
    for base_dir in base_dirs:
        if not os.path.exists(base_dir): continue
        for root, _, files in os.walk(base_dir):
            for file in files:
                if file.lower().endswith(('.jpg', '.png', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
    return image_paths

def extract_label_and_platform(path):
    # ì½”ë© í™˜ê²½ìš© ê²½ë¡œ êµ¬ë¶„ì '/'ì— ìµœì í™”
    normalized_path = path.replace('\\', '/')
    parts = normalized_path.split('/')
    work_id = parts[-3] if len(parts) >= 3 else "Unknown_Work"
    platform = "Unknown_Platform"
    if "Naver" in path or "naver" in path: platform = "Naver"
    elif "Kakao" in path or "kakao" in path: platform = "Kakao"
    return work_id, platform

class WebtoonFinetuneDataset(Dataset):
    def __init__(self, data_list, label_to_idx, transform=None):
        self.data_list = data_list
        self.transform = transform
        self.label_to_idx = label_to_idx

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, idx):
        path, platform = self.data_list[idx]

        try:
            img = Image.open(path).convert("RGB")
        except:
            return torch.zeros(3, 320, 320), -1, platform

        if self.transform:
            img = self.transform(img)

        work_id, _ = extract_label_and_platform(path)
        label = self.label_to_idx.get(work_id, -1)

        return img, label, platform


# =================================================================
# âœ… ë©”ì¸ í•™ìŠµ ë¸”ë¡
# =================================================================
if __name__ == '__main__':
    print(f"ğŸ”¥ ë„¤ì´ë²„ ì›¹íˆ° ì‘í’ˆ ID ë¶„ë¥˜ 3ì°¨ ë¯¸ì„¸ ì¡°ì • ì‹œì‘ (Batch Size: {BATCH_SIZE}, Augmentation ì ìš©)")
    print(f"âœ… ì‚¬ìš© ì¥ì¹˜: {DEVICE}")

    # 1. ì „ì²´ ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘ ë° 3ë¶„í•  (ë„¤ì´ë²„ ë°ì´í„°ë§Œ ì‚¬ìš©)
    all_image_paths = collect_image_paths([NAVER_ROOT_DIR])
    random.shuffle(all_image_paths)

    total_size = len(all_image_paths)
    if total_size == 0:
        print("ğŸš¨ ì˜¤ë¥˜: ë°ì´í„° ê²½ë¡œì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Google Drive ë§ˆìš´íŠ¸ ë° ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        exit()

    test_size = int(total_size * TEST_RATIO)
    val_size = int(total_size * VAL_RATIO)

    test_image_paths = all_image_paths[:test_size]
    val_image_paths = all_image_paths[test_size : test_size + val_size]
    train_image_paths = all_image_paths[test_size + val_size :]

    # 2. ë¼ë²¨ ì •ì˜ ë° ì¸ë±ìŠ¤ ë§¤í•‘
    all_labels = set(extract_label_and_platform(p)[0] for p in all_image_paths)
    if "Unknown_Work" in all_labels: all_labels.remove("Unknown_Work")
    sorted_labels = sorted(list(all_labels))
    label_to_idx = {label: idx for idx, label in enumerate(sorted_labels)}
    num_classes = len(sorted_labels)
    print(f"ì‘í’ˆ ID (í´ë˜ìŠ¤): {num_classes}ê°œ")
    print(f"ë°ì´í„° í¬ê¸°: Train={len(train_image_paths)}, Val={len(val_image_paths)}, Test={len(test_image_paths)}")

    # 3. ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ì¤€ë¹„
    def create_data_list(paths):
        return [(path, extract_label_and_platform(path)[1]) for path in paths]

    train_data_list = create_data_list(train_image_paths)
    val_data_list = create_data_list(val_image_paths)
    test_data_list = create_data_list(test_image_paths)

    train_dataset = WebtoonFinetuneDataset(train_data_list, label_to_idx, transform_train)
    val_dataset = WebtoonFinetuneDataset(val_data_list, label_to_idx, transform_basic)
    test_dataset = WebtoonFinetuneDataset(test_data_list, label_to_idx, transform_basic)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)

    # 4. ëª¨ë¸ ë¡œë“œ ë° í•™ìŠµ ì¤€ë¹„
    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
    num_features = model.fc.in_features
    model.fc = nn.Linear(num_features, num_classes)

    if PRETRAIN_PATH and os.path.exists(PRETRAIN_PATH):
        model.load_state_dict(torch.load(PRETRAIN_PATH, map_location=DEVICE))
        print(f"âœ… 2ì°¨ í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ: {PRETRAIN_PATH}")

    for param in model.parameters(): param.requires_grad = True
    model = model.to(DEVICE)

    criterion = nn.CrossEntropyLoss(ignore_index=-1)
    optimizer = optim.Adam(model.parameters(), lr=LR)
    best_val_acc = 0.0

    # 5. í•™ìŠµ ë£¨í”„
    print(f"ğŸ”¥ í•™ìŠµ ì‹œì‘...")
    for epoch in range(EPOCHS):
        model.train()
        total_loss, correct, total = 0, 0, 0

        # tqdm ëŒ€ì‹  printë¡œ ì§„í–‰ ìƒí™© ì¶œë ¥ (ì½”ë© í™˜ê²½ì—ì„œ tqdm ëŒ€ì‹  ì‚¬ìš©í•  ìˆ˜ ìˆìŒ)
        for batch_idx, (imgs, labels, _) in enumerate(train_loader):
            valid_mask = (labels != -1)
            imgs = imgs[valid_mask].to(DEVICE)
            labels = labels[valid_mask].to(DEVICE)

            if len(labels) == 0: continue

            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += len(labels)

            if (batch_idx + 1) % 100 == 0: # 100 ë°°ì¹˜ë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥
                print(f"Epoch [{epoch+1}/{EPOCHS}] Batch [{batch_idx+1}/{len(train_loader)}] Loss: {loss.item():.4f}")

        train_acc = correct / total if total > 0 else 0

        # === ê²€ì¦ (Validation) ===
        model.eval()
        val_correct, val_total = 0, 0
        with torch.no_grad():
            for imgs, labels, _ in val_loader:
                valid_mask = (labels != -1)
                imgs = imgs[valid_mask].to(DEVICE)
                labels = labels[valid_mask].to(DEVICE)

                if len(labels) == 0: continue

                outputs = model(imgs)
                _, preds = torch.max(outputs, 1)
                val_correct += (preds == labels).sum().item()
                val_total += len(labels)

        val_acc = val_correct / val_total if val_total > 0 else 0

        print(f"--- Epoch [{epoch+1}/{EPOCHS}] ì™„ë£Œ --- | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}")

        # ëª¨ë¸ ì €ì¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), OUTPUT_MODEL_PATH)
            print(f"â­ Best Model Saved! Val Acc: {best_val_acc:.4f}")

    # 6. ìµœì¢… í…ŒìŠ¤íŠ¸ (ìµœì¢… ëª¨ë¸ ì‚¬ìš©)
    model.load_state_dict(torch.load(OUTPUT_MODEL_PATH, map_location=DEVICE))
    model.eval()
    test_correct, test_total = 0, 0
    with torch.no_grad():
        for imgs, labels, _ in test_loader:
            valid_mask = (labels != -1)
            imgs = imgs[valid_mask].to(DEVICE)
            labels = labels[valid_mask].to(DEVICE)

            if len(labels) == 0: continue

            outputs = model(imgs)
            _, preds = torch.max(outputs, 1)
            test_correct += (preds == labels).sum().item()
            test_total += len(labels)

    final_test_acc = test_correct / test_total if test_total > 0 else 0
    print(f"\n--- 3ì°¨ í•™ìŠµ ìµœì¢… ê²°ê³¼ ---")
    print(f"âœ¨ ìµœì¢… Test ì •í™•ë„: {final_test_acc:.4f}")
    print(f"ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {OUTPUT_MODEL_PATH}")